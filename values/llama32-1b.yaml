# Llama 3.2 1B Model Configuration
model:
  name: llama32-1b
  fullName: llama3.2:1b
  displayName: "Llama 3.2 1B"
  url: "https://ollama.com/library/llama3.2:1b"
  size: "1.3GB"

deployment:
  name: "ollama-llama32-1b"
  namespace: "llama32-1b"
  image: "ollama/ollama:0.11.10"
  replicas: 1
  resources:
    requests:
      cpu: "500m"
      memory: "2Gi"
    limits:
      cpu: "2"
      memory: "4Gi"

service:
  name: "ollama-llama32-1b-service"
  port: 11434
  targetPort: 11434

nfsServer:
  enabled: true
  image: "boyroywax/nfs-server:1.0.0"
  name: "nfs-server-llama32-1b"
  storageSize: "20Gi"
  resources:
    requests:
      cpu: "100m"
      memory: "256Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"

ingress:
  enabled: true
  className: "nginx"
  host: "llama32-1b.ollama.ai.layerwork.space"
  path: "/"
  tls:
    enabled: true
    secretName: "llama32-1b-tls"

modelDownloadJob:
  enabled: true
  name: "download-llama32-1b"
  image: "ollama/ollama:0.11.10"
  backoffLimit: 3

# Node affinity and tolerations (optional)
# Uncomment and configure these if you want to schedule pods on specific nodes
#
# For dedicated AI nodes with taints:
# tolerations:
#   - key: "ai-workload"
#     operator: "Equal"
#     value: "true"
#     effect: "NoSchedule"
#
# For nodes labeled for AI workloads:
# affinity:
#   nodeAffinity:
#     requiredDuringSchedulingIgnoredDuringExecution:
#       nodeSelectorTerms:
#       - matchExpressions:
#         - key: "kubernetes.io/arch"
#           operator: In
#           values:
#           - "amd64"
#         - key: "node-role.kubernetes.io/ai"
#           operator: Exists

# Node affinity to use the dedicated llama32-1b node
tolerations:
  - key: "ollama"
    operator: "Equal"
    value: "dedicated"
    effect: "NoSchedule"

affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: "kubernetes.io/arch"
          operator: In
          values:
          - "amd64"
        - key: "node-role.kubernetes.io/llama32-1b"
          operator: Exists
