# Meta Llama 3.1 8B Model Configuration
model:
  name: llama31-8b
  fullName: llama3.1:8b
  displayName: "Meta Llama 3.1 8B"
  url: "https://ollama.com/library/llama3.1"
  size: "4.7GB"

# Namespace configuration
namespace:
  create: true

# NFS configuration for Llama 3.1 8B model
nfs:
  image:
    repository: boyroywax/nfs-server
    tag: 1.0.0
    pullPolicy: IfNotPresent
  storage:
    size: 25Gi  # Storage for Llama 3.1 8B
    storageClass: do-block-storage
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  securityContext:
    runAsUser: 0
    runAsGroup: 0
    fsGroup: 1001
    privileged: true

# Ollama configuration optimized for Llama 3.1 8B
ollama:
  image:
    repository: ollama/ollama
    tag: "0.11.10"
    pullPolicy: IfNotPresent
  replicaCount: 1
  
  resources:
    requests:
      memory: "6Gi"  # Memory for Llama 3.1 8B
      cpu: "1000m"
    limits:
      memory: "12Gi"  # High limit for 8B parameter model
      cpu: "3000m"
  
  probes:
    readiness:
      enabled: true
      httpGet:
        path: /
        port: 11434
      initialDelaySeconds: 45
      periodSeconds: 15
    liveness:
      enabled: true
      httpGet:
        path: /
        port: 11434
      initialDelaySeconds: 90
      periodSeconds: 45

# Service configuration
service:
  type: ClusterIP
  port: 11434
  targetPort: 11434

# Ingress configuration
ingress:
  enabled: true
  className: nginx
  host: llama31-8b.ollama.ai.layerwork.space
  path: /
  pathType: Prefix
  tls:
    enabled: true
    secretName: llama31-8b-tls

# Model download job configuration
modelDownload:
  enabled: true
  image:
    repository: ollama/ollama
    tag: "0.11.10"
  backoffLimit: 4
  resources:
    requests:
      memory: "4Gi"
      cpu: "1000m"
    limits:
      memory: "6Gi"
      cpu: "1500m"

# Node affinity with flexible scheduling
tolerations:
  - key: "ollama"
    operator: "Equal"
    value: "dedicated"
    effect: "NoSchedule"

affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      preference:
        matchExpressions:
        - key: "node-role.kubernetes.io/llama31-8b"
          operator: Exists
    - weight: 50
      preference:
        matchExpressions:
        - key: "kubernetes.io/arch"
          operator: In
          values:
          - "amd64"
